%! Author = borisdeletic
%! Date = 09/05/2023

% Preamble
\documentclass[11pt]{article}

% Document
\begin{document}

\section{Hamiltonian Monte Carlo}\label{sec:hamiltonian_monte_carlo}
    Hamiltonian Monte Carlo (HMC) is a powerful Markov-Chain Monte-Carlo (MCMC) method used to effectively generate
    random samples from a probability distribution.
    HMC was originally developed for Lattice QCD~\cite{HMC_Duane}, but has since found wide applications in statistical
    physics, computational biology, and machine learning.
    The most significant advantage of HMC is its ability to sample from very high dimensional ($D$ > millions)
    complex distributions, which is currently unmatched by other MCMC algorithms.

\subsection{Metropolis--Hastings Algorithm}\label{subsec:metropolis_hastings}
    HMC is a subclass of the Metropolis--Hastings algorithm~\cite{Metropolis_OG}, a MCMC method which comprises of two
    steps: a proposal and a correction.
    Given an initial state $\theta$, a new sample $\theta'$ is proposed using some stochastic process.
    The proposal is then corrected to ensure detailed-balance so the Markov-Chain converges to the
    target distribution $\pi(\theta)$.
    The correction is performed by choosing to keep the new sample with an acceptance probability
    \begin{equation}\label{eq:metropolis_hastings}
        A(\theta' | \theta) = \min \left(1, \frac{Q(\theta | \theta') \pi(\theta') }{Q(\theta' | \theta) \pi(\theta) } \right),
    \end{equation}
    where $Q(\theta | \theta')$ is the probability distribution of the proposal function.
    All methods we will explore have symmetric proposal distributions $Q(\theta | \theta') = Q(\theta' | \theta)$,
    such that the acceptance probability reduces to
    \begin{equation}\label{eq:metropolis}
        A(\theta' | \theta) = \min \left(1, \frac{\pi(\theta') }{\pi(\theta) } \right).
    \end{equation}

    With a set of $N$ samples generated by Metropolis--Hastings, $\{ \theta_i \}$, we can estimate expected values of observables
    of the target distribution as
    \begin{equation}\label{eq:mcmc_observable}
    \begin{aligned}
        \langle \mathcal{O} \rangle = \frac{1}{N}\sum_{i=0}^N \mathcal{O}(\theta_i).
    \end{aligned}
    \end{equation}

\subsection{Hamiltonian Dynamics}\label{subsec:hamiltonian_dynamics}
    Hamiltonian dynamics is a formulation in classical physics based on the principle of least action.
    It generalises a system to its position $\mathbf{q}$ and conjugate momenta $\mathbf{p}$ in order to solve problems
    by working in \emph{phase space}.

    The principle of least action states that the equations of motion of a system are given by the stationary point of
    the action functional.
    The action is defined as
    \begin{equation}\label{eq:action_definition}
    \begin{aligned}
        S = \int  \mathcal{L}(\mathbf{q}, \mathbf{\dot{q}}) dt,
    \end{aligned}
    \end{equation}
    where $\mathcal{L}(\mathbf{q}, \mathbf{\dot{q}})$ is the Lagrangian (not to be confused with likelihood).

    The Hamiltonian is then defined as the Legendre transform of the Lagrangian given by
    \begin{equation}\label{eq:hamiltonian_definition}
    \begin{aligned}
        H(\mathbf{q}, \mathbf{p}) = \mathbf{\dot{q}} \cdot \mathbf{p} - \mathcal{L}
    \end{aligned}
    \end{equation}
    with conjugate momenta defined as $p_i = \partial \mathcal{L} / \partial \dot{q_i}$.

    Using the Euler--Lagrange equations to solve for the stationary point of the action yields the equations of motion
    \begin{equation}\label{eq:hamiltonian_motion}
    \begin{aligned}
        \frac{dq_i}{dt} = \frac{\partial H}{\partial p_i}, \quad \frac{dp_i}{dt} = -\frac{\partial H}{\partial q_i},
    \end{aligned}
    \end{equation}
    which can be integrated to find the trajectory.

\subsection{HMC Algorithm}\label{subsec:hmc_algorithm}
    HMC derives its strengths from incorporating the use of Hamiltonian dynamics to generate new samples in the Markov-Chain.
    The main idea is to treat the parameters $\theta$ as a position and introduce an auxiliary momentum variable $p$.
    Then, treating the target distribution as a potential energy, we can navigate the landscape by solving Hamilton's
    equations~\eqref{eq:hamiltonian_motion} and integrating the trajectory from $(\theta_0, p_0)$ to a new point
    $(\theta_1, p_1)$.
    Finally, a correction step is performed as described in~\eqref{eq:metropolis_hastings} and the new sample is accepted
    to the Markov-Chain with a given probability.

    Suppose we are trying to sample from a target distribution $\pi(\theta)$, the Hamiltonian for HMC is defined as
    \begin{equation}\label{eq:hmc_hamiltonian}
    \begin{aligned}
        H = \frac{1}{2} \mathbf{p}^T M^{-1} \mathbf{p} - \log \pi,
    \end{aligned}
    \end{equation}
    where $M$ is a mass matrix known as the \emph{metric}, and $\mathbf{p}$ is a new momentum variable we have introduced.
    Intuitively, this treats the Markov-Chain point as a $D$ dimensional particle moving through a
    potential well $U(\theta) = -\log \pi(\theta)$.

    The momentum is stochastically drawn from a normal distribution,
    $\mathbf{p} \sim \mathcal{N}(0, \sigma = M)$.
    The metric therefore defines the region of phase space HMC explores and is an important input parameter to
    tune for effective sampling~\cite{betancourt2016energymetric}.

    Once the Hamiltonian is obtained, the equations of motion~\eqref{eq:hamiltonian_motion} are numerically integrated
    to give a new sample $(\theta_0, p_0)$ \rightarrow $(\theta_1, p_1)$.
    In order to solve the equations of motion we therefore rely on the \emph{gradient} of the
    distribution $\nabla \log \pi(\theta)$.
    This often presents a practical difficult as not many distributions have easily accessible gradients, however this
    can be alleviated using \emph{auto differentiation}~\cite{carpenter2015stan, NEURIPS2020_9332c513, 10.5555/3571885.3571964}
    as discussed further in~\cref{sec:autodiff}.


\subsection{Leapfrog Integrator}\label{subsec:integrator}
    When choosing a numerical integrator to solve Hamilton's equations, a few considerations must be taken into account.
    To maintain detailed balance in HMC, our system must exhibit time-reversibility so that the proposal distribution
    remains symmetric.
    Under T-symmetry where all momenta are reversed $\mathbf{p} \rightarrow -\mathbf{p}$, the equations of motion are
    time-reversible, therefore the probability of generating any two points is
    symmetric $(\theta_0, p_0) \leftrightarrow (\theta_1, p_1)$.

    In practice however, not all numerical solvers preserve time-reversibility, and we must take care which algorithm to use.
    One such class of solvers is \emph{symplectic integrators}, which guarantee time-reversibility.

    The leapfrog integrator is a symplectic integrator and proves an attractive candidate due to its simplicity.
    Given a step size $\epsilon$ and path length $L$, we can update the position $\theta$ and momentum $p$ at each iteration $t$.
    \begin{algorithm}
    \caption{Leapfrog Integrator}
    \label{alg:leapfrog_integrator}
    \begin{algorithmic}
        \FOR{$0 < t < L$}
        \STATE \COMMENT{First momentum half step}
        \STATE $\mathbf{p}_{t+1/2} \gets \mathbf{p}_t - \frac{1}{2} \epsilon \nabla U(\mathbf{\theta}_t)$
        \STATE
        \STATE $ \mathbf{\theta}_{t+1} \gets \mathbf{\theta}_t + \epsilon \mathbf{p}_{t+1/2}$
        \STATE
        \STATE $ \mathbf{p}_{t+1} \gets \mathbf{p}_{t+1/2} - \frac{1}{2} \epsilon \nabla U(\mathbf{\theta}_{t+1})$
        \ENDFOR
    \end{algorithmic}
    \end{algorithm}

    While theoretically the Hamiltonian satisfies the principle of energy conservation, the use of the leapfrog
    integration introduces an energy drift and the total energy can change during the evolution.

    To correct for this, a Metropolis step is performed to choose whether to accept or reject the sample in
    the Markov-Chain based on it's change in energy.
    The acceptance probability is given by
    \begin{equation}\label{eq:hmc_accept_prob}
    \begin{aligned}
        A(\theta' | \theta) = \min \left(1, \frac{\exp(-H(\theta_1, q_1)) }{\exp(-H(\theta_0, q_0)) } \right),
    \end{aligned}
    \end{equation}
    which maintains detailed balance of the target distribution~\cite{betancourt2018conceptual}.

\subsection{HMC Parameters}\label{subsec:hmc_params}
    The three main input parameters for HMC are the step size $\epsilon$, path length $L$, and metric $M$.
    It is essential to properly tune these parameters for each distribution to ensure functioning sampling.

    The step size $\epsilon$ affects the accuracy of numerical integration and therefore the change in energy between the initial
    and final point $\Delta H = H(\theta_1, q_1) - H(\theta_0, q_0)$.
    Choosing $\epsilon$ to be too large will result in high rejection rates during the correction step,
    while an $\epsilon$ too small will lead to longer integration
    time ($L\epsilon$), both wasting computational resources.

    The path length $L$ with $\epsilon$ defines the integration time $L\epsilon$ of the numerical integration.
    It is important for the integration time to be long enough such that the proposal point is sufficiently decorrelated
    from the initial point.

    Considering the Hamiltonian from an energy perspective $H(E)$, the metric defines the distribution of energy level
    sets which HMC explores.
    The metric must be properly chosen such that the momenta drawn adequately explore the target distribution level
    sets~\cite{betancourt2016energymetric}.

\subsection{Critical Slowing Down}\label{subsec:critical_slowing}
    For a well functioning MCMC algorithm, the sequence of samples in the Markov-Chain must be uncorrelated and
    effectively independent.
    Define the autocorrelation of an observable $\mathcal{O}$ is defined as
    \begin{equation}\label{eq:autocorrelation}
    \begin{aligned}
        C_{\mathcal{O}}(\tau) = \langle \mathcal{O}(t) \mathcal{O}(t + \tau) \rangle,
    \end{aligned}
    \end{equation}
    where $t$ denotes the discrete time of the Markov-Chain, and $\langle \cdot \rangle$ denotes the time average.

    The autocorrelation time characterises how long it takes for the Markov-Chain to generate an independent sample,
    and is defined as
    \begin{equation}\label{eq:autocorrelation_time}
    \begin{aligned}
        \tau_{\mathcal{O}, \text{int}} = \frac{1}{C_{\mathcal{O}}(0)} \sum_{t=1}^T C_{\mathcal{O}}(t).
    \end{aligned}
    \end{equation}

    As the target distribution approaches a critical point, the autocorrelation time dramatically increases, a phenomena
    known as critical slowing down.

\subsection{Sampling within an Iso-Likelihood Contour}\label{subsec:isolikelood_sampling}
    Nested sampling requires that samples are generated subject to the hard likelihood constraint
    $\mathcal{L} > \mathcal{L}_i$ at each iteration.
    It is a challenging problem to draw points from the constrained distribution, with current approaches such as
    slice sampling~\cite{neal2003slice} and rejection sampling~\cite{Feroz_2009} scaling poorly with dimension.

    HMC samples from the unconstrained distribution $\pi(\theta)$.
    In order to leverage its use in nested sampling, it is therefore necessary to modify the algorithm to sample
    given a constraint.
\end{document}