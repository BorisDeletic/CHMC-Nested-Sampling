%! Author = borisdeletic
%! Date = 09/05/2023

% Preamble
\documentclass[11pt]{article}

% Document
\begin{document}

\section{Hamiltonian Monte Carlo}\label{sec:hamiltonian_monte_carlo}
    Hamiltonian Monte Carlo (HMC) is a powerful Markov-Chain Monte-Carlo (MCMC) method used to effectively generate
    random samples from a probability distribution.
    HMC was originally developed for Lattice QCD~\cite{HMC_Duane}, but has since found wide applications in statistical
    physics, computational biology, and machine learning.
    The most significant advantage of HMC is its ability to sample from very high dimensional ($D$ > millions)
    complex distributions, which is currently unmatched by other MCMC algorithms.

\subsection{Metropolis-Hastings Algorithm}\label{subsec:metropolis_hastings}
    HMC is a subclass of the Metropolis-Hastings algorithm~\cite{Metropolis_OG}, a MCMC which comprises of two
    steps: a proposal and a correction.
    Given an initial state $\theta$, a new sample $\theta'$ is proposed using some stochastic process.
    The proposal is then corrected to ensure detailed-balance so the Markov-Chain converges to the
    target distribution $\pi(\theta)$.
    The correction is performed by choosing to keep the new sample with an acceptance probability
    \begin{equation}\label{eq:metropolis_hastings}
        A(\theta' | \theta) = \min \left(1, \frac{Q(\theta | \theta') \pi(\theta') }{Q(\theta' | \theta) \pi(\theta) } \right),
    \end{equation}
    where $Q(\theta | \theta')$ is the probability distribution of the proposal function.
    All methods we will explore have symmetric proposal distributions $Q(\theta | \theta') = Q(\theta; | \theta)$,
    such that the acceptance probability reduces to
    \begin{equation}\label{eq:metropolis}
        A(\theta' | \theta) = \min \left(1, \frac{\pi(\theta') }{\pi(\theta) } \right).
    \end{equation}

    With a set of $N$ samples generated by Metropolis-Hastings, $\{ \theta_i \}$, we can estimate expected values of observables
    of the target distribution as
    \begin{equation}\label{eq:mcmc_observable}
    \begin{aligned}
        \langle \mathcal{O} \rangle = \frac{1}{N}\sum_{i=0}^N \mathcal{O}(\theta_i).
    \end{aligned}
    \end{equation}

\subsection{Hamiltonian Mechanics}\label{subsec:hamiltonian_mechanics}

    Hamiltonian Dynamics
    HMC and sympletic integrators
    Parameters, epsilon, path length, metric.

    section on autodiff

    section on critical slowing down.

    final section: Sampling from a constrained distribution within the iso-likelihood contour is a challenging problem.
\end{document}